---
permalink: /
title: "Academic Pages is a ready-to-fork GitHub Pages template for academic personal websites"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a student currently engaged in research on large language models (LLMs) and their safety evaluation. My work primarily focuses on enhancing the confidence expression ability of LLMs, using techniques such as cognitive diagnosis and experience-based learning approaches to improve model self-evaluation and calibration of safety confidence levels.

### Research Interests:
- **Large Language Models (LLMs)**: Safety, confidence calibration, and performance enhancement.
- **Safety Evaluation**: Fine-grained security risk classification and automated evaluation methods.
- **Cognitive Diagnosis**: Methods for improving model confidence and trustworthiness.
- **Model Robustness and Security**: Adversarial testing and ensuring model safety in real-world applications.

### Current Projects:
- **Confidence Calibration for LLMs**: Developing methods to improve model confidence through semantic mutation and self-consistency approaches.
- **Automated Safety Evaluation Tools**: Designing and testing automated systems for real-time safety assessment of LLM-generated content across multiple security dimensions.
- **Red Teaming**: Using reinforcement learning algorithms to test and strengthen the security and robustness of LLMs.

Feel free to reach out for collaboration opportunities or any inquiries related to my research!

---

### Contact Information:
- **Email**: [your.email@example.com]
- **GitHub**: [Your GitHub Profile](https://github.com/your-username)
- **LinkedIn**: [Your LinkedIn Profile](https://www.linkedin.com/in/your-profile)
